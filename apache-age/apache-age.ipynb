{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1af50d",
   "metadata": {},
   "source": [
    "# Apache AGE\n",
    "\n",
    "\n",
    "## Deploy:\n",
    "\n",
    "\n",
    "```\n",
    "$ docker run \\\n",
    "    --name age \\\n",
    "    -p 5455:5432 \\\n",
    "    -e POSTGRES_USER=postgresUser \\\n",
    "    -e POSTGRES_PASSWORD=postgresPW \\\n",
    "    -e POSTGRES_DB=postgresDB \\\n",
    "    apache/age\n",
    "    \n",
    "$ docker exec -it age psql -U postgresUser -d postgres\n",
    "> CREATE EXTENSION IF NOT EXISTS age;\n",
    "> LOAD 'age';\n",
    "> SET search_path = ag_catalog, \"$user\", public;\n",
    "\n",
    "ou \n",
    "\n",
    "> ALTER SYSTEM SET session_preload_libraries = 'age'; (por padrão)\n",
    "> SELECT pg_reload_conf();\n",
    "> SHOW session_preload_libraries;\n",
    "```\n",
    "\n",
    "\n",
    "## Observações:\n",
    " * Não tem integração com o Spark https://github.com/apache/age/issues/1122\n",
    " * Usa Cipher;\n",
    " * Mesmo usando o protocolo JDBC, não é possível carregar vértices e arestas;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54919bc",
   "metadata": {},
   "source": [
    "## Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f1cba5-b7b4-44cb-9d90-dba9acb86072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg2-binary in /home/lucasmsp/.local/lib/python3.10/site-packages (2.9.5)\n",
      "Collecting antlr4-python3-runtime\n",
      "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
      "Collecting apache-age-python\n",
      "  Downloading apache_age_python-0.0.7-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: psycopg2 in /home/lucasmsp/.local/lib/python3.10/site-packages (from apache-age-python) (2.8.6)\n",
      "Collecting antlr4-python3-runtime\n",
      "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl.metadata (291 bytes)\n",
      "Downloading apache_age_python-0.0.7-py3-none-any.whl (25 kB)\n",
      "Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, apache-age-python\n",
      "Successfully installed antlr4-python3-runtime-4.11.1 apache-age-python-0.0.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary antlr4-python3-runtime apache-age-python\n",
    "# Último update em  22 de set. de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d755dd87-aae3-47b6-b713-1592f0d53b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import age\n",
    "import psycopg2\n",
    "\n",
    "# Configuração de conexão\n",
    "GRAPH_NAME = \"exemplo_grafo\"\n",
    "CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5455\",\n",
    "    \"dbname\": \"postgresDB\", \n",
    "    \"user\": \"postgresUser\",\n",
    "    \"password\": \"postgresPW\"\n",
    "}\n",
    "\n",
    "def conectar_age():\n",
    "    \"\"\"Estabelece conexão com Apache AGE\"\"\"\n",
    "    try:\n",
    "        # Conectar usando age driver\n",
    "        connection = age.connect(\n",
    "            graph=GRAPH_NAME,\n",
    "            dsn=f\"host={CONFIG['host']} port={CONFIG['port']} dbname={CONFIG['dbname']} user={CONFIG['user']} password={CONFIG['password']}\"\n",
    "        )\n",
    "        \n",
    "        return connection\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na conexão: {e}\")\n",
    "        return None\n",
    "\n",
    "# Estabelecer conexão\n",
    "conn = conectar_age()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2338b2e5-970a-4bdd-a5d7-bae6dd3415a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pessoa criada: {label:Pessoa, id:1688849860263937, properties:{nome: Joao Silva, idade: 35, profissao: Engenheiro, }}::VERTEX\n",
      "Pessoa criada: {label:Pessoa, id:1688849860263938, properties:{nome: Maria Santos, idade: 29, profissao: Designer, }}::VERTEX\n",
      "Pessoa criada: {label:Pessoa, id:1688849860263939, properties:{nome: Carlos Lima, idade: 42, profissao: Gerente, }}::VERTEX\n",
      "Pessoa criada: {label:Pessoa, id:1688849860263940, properties:{nome: Ana Costa, idade: 31, profissao: Analista, }}::VERTEX\n"
     ]
    }
   ],
   "source": [
    "# Criar vértices (pessoas)\n",
    "pessoas = [\n",
    "    \"CREATE (p:Pessoa {nome: 'Joao Silva', idade: 35, profissao: 'Engenheiro'}) RETURN p\",\n",
    "    \"CREATE (p:Pessoa {nome: 'Maria Santos', idade: 29, profissao: 'Designer'}) RETURN p\", \n",
    "    \"CREATE (p:Pessoa {nome: 'Carlos Lima', idade: 42, profissao: 'Gerente'}) RETURN p\",\n",
    "    \"CREATE (p:Pessoa {nome: 'Ana Costa', idade: 31, profissao: 'Analista'}) RETURN p\"\n",
    "]\n",
    "\n",
    "# Executar queries de criação de pessoas\n",
    "for query in pessoas:\n",
    "    cursor = conn.execCypher(query)\n",
    "    for row in cursor:\n",
    "        print(f\"Pessoa criada: {row[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8854c9c-da85-4802-af1a-9f67ea1eb070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empresa criada: {label:Empresa, id:1970324836974593, properties:{nome: TechCorp, setor: Tecnologia, funcionarios: 500, }}::VERTEX\n",
      "Empresa criada: {label:Empresa, id:1970324836974594, properties:{nome: DesignStudio, setor: Design, funcionarios: 50, }}::VERTEX\n",
      "Empresa criada: {label:Empresa, id:1970324836974595, properties:{nome: ConsultingGroup, setor: Consultoria, funcionarios: 200, }}::VERTEX\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar vértices (empresas)\n",
    "empresas = [\n",
    "    \"CREATE (e:Empresa {nome: 'TechCorp', setor: 'Tecnologia', funcionarios: 500}) RETURN e\",\n",
    "    \"CREATE (e:Empresa {nome: 'DesignStudio', setor: 'Design', funcionarios: 50}) RETURN e\",\n",
    "    \"CREATE (e:Empresa {nome: 'ConsultingGroup', setor: 'Consultoria', funcionarios: 200}) RETURN e\"\n",
    "]\n",
    "\n",
    "for query in empresas:\n",
    "    cursor = conn.execCypher(query)\n",
    "    for row in cursor:\n",
    "        print(f\"Empresa criada: {row[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be51f933-d4f5-45cf-adde-ee524b9d4168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relacionamento criado\n",
      "Relacionamento criado\n",
      "Relacionamento criado\n",
      "Relacionamento criado\n"
     ]
    }
   ],
   "source": [
    "# Criar relacionamentos\n",
    "relacionamentos = [\n",
    "    \"MATCH (p:Pessoa {nome: 'Joao Silva'}), (e:Empresa {nome: 'TechCorp'}) CREATE (p)-[:TRABALHA_EM {cargo: 'Engenheiro Senior', salario: 8500}]->(e)\",\n",
    "    \"MATCH (p:Pessoa {nome: 'Maria Santos'}), (e:Empresa {nome: 'DesignStudio'}) CREATE (p)-[:TRABALHA_EM {cargo: 'Designer Pleno', salario: 6000}]->(e)\",\n",
    "    \"MATCH (p:Pessoa {nome: 'Carlos Lima'}), (e:Empresa {nome: 'ConsultingGroup'}) CREATE (p)-[:TRABALHA_EM {cargo: 'Gerente', salario: 12000}]->(e)\",\n",
    "    \"MATCH (p:Pessoa {nome: 'Ana Costa'}), (e:Empresa {nome: 'TechCorp'}) CREATE (p)-[:TRABALHA_EM {cargo: 'Analista', salario: 4500}]->(e)\"\n",
    "]\n",
    "\n",
    "for query in relacionamentos:\n",
    "    cursor = conn.execCypher(query)\n",
    "    print(\"Relacionamento criado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "328dfba7-5211-4a5b-98a5-0b946a70daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amizade criada\n",
      "Amizade criada\n"
     ]
    }
   ],
   "source": [
    "# Relacionamentos pessoais\n",
    "amizades = [\n",
    "    \"MATCH (p1:Pessoa {nome: 'Joao Silva'}), (p2:Pessoa {nome: 'Maria Santos'}) CREATE (p1)-[:CONHECE {proximidade: 'amigo_proximo'}]->(p2)\",\n",
    "    \"MATCH (p1:Pessoa {nome: 'Maria Santos'}), (p2:Pessoa {nome: 'Carlos Lima'}) CREATE (p1)-[:CONHECE {proximidade: 'conhecido'}]->(p2)\"\n",
    "]\n",
    "\n",
    "for query in amizades:\n",
    "    cursor = conn.execCypher(query)\n",
    "    print(\"Amizade criada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "288f16d1-21ad-4b78-a753-a1308a414a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Commit das mudanças\n",
    "conn.commit()\n",
    "print(\"Grafo criado com sucesso!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea7807f-1782-4ae3-9956-7cdafbaf03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PESSOAS ENCONTRADAS ===\n",
      "Nome: Joao Silva, Idade: 35, Profissão: Engenheiro\n",
      "Nome: Maria Santos, Idade: 29, Profissão: Designer\n",
      "Nome: Carlos Lima, Idade: 42, Profissão: Gerente\n",
      "Nome: Ana Costa, Idade: 31, Profissão: Analista\n"
     ]
    }
   ],
   "source": [
    "ag = conectar_age()\n",
    "\n",
    "with ag.connection.cursor() as cursor:\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM cypher('exemplo_grafo', $$\n",
    "        MATCH (p:Pessoa) \n",
    "        RETURN p.nome, p.idade, p.profissao\n",
    "    $$) AS (nome agtype, idade agtype, profissao agtype);\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    print(\"=== PESSOAS ENCONTRADAS ===\")\n",
    "    for row in results:\n",
    "        print(f\"Nome: {row[0]}, Idade: {row[1]}, Profissão: {row[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2817377-083a-4958-a4ad-0027e17a51a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTE BÁSICO DO GRAFO ===\n",
      "Sucesso: 1 resultado(s)\n",
      "  1: (16973, 'exemplo_grafo', 'exemplo_grafo')\n",
      "\n",
      "=== COUNT SIMPLES ===\n",
      "Sucesso: 1 resultado(s)\n",
      "  1: (7,)\n",
      "\n",
      "=== RETORNA VÉRTICES COMPLETOS ===\n",
      "Sucesso: 4 resultado(s)\n",
      "  1: ({label:Pessoa, id:1688849860263937, properties:{nome: Joao Silva, idade: 35, profissao: Engenheiro, }}::VERTEX,)\n",
      "  2: ({label:Pessoa, id:1688849860263938, properties:{nome: Maria Santos, idade: 29, profissao: Designer, }}::VERTEX,)\n",
      "  3: ({label:Pessoa, id:1688849860263939, properties:{nome: Carlos Lima, idade: 42, profissao: Gerente, }}::VERTEX,)\n",
      "\n",
      "=== UMA PROPRIEDADE ESPECÍFICA ===\n",
      "Sucesso: 4 resultado(s)\n",
      "  1: ('Joao Silva',)\n",
      "  2: ('Maria Santos',)\n",
      "  3: ('Carlos Lima',)\n",
      "\n",
      "=== MÚLTIPLAS PROPRIEDADES ===\n",
      "Sucesso: 4 resultado(s)\n",
      "  1: ('Joao Silva', 35, 'Engenheiro')\n",
      "  2: ('Maria Santos', 29, 'Designer')\n",
      "  3: ('Carlos Lima', 42, 'Gerente')\n"
     ]
    }
   ],
   "source": [
    "ag = conectar_age()\n",
    "    \n",
    "# Testes progressivos\n",
    "tests = [\n",
    "    {\n",
    "        'nome': 'Teste básico do grafo',\n",
    "        'query': \"SELECT * FROM ag_graph WHERE name = 'exemplo_grafo';\"\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Count simples',\n",
    "        'query': \"\"\"\n",
    "        SELECT * FROM cypher('exemplo_grafo', $$\n",
    "            MATCH (n) \n",
    "            RETURN count(n)\n",
    "        $$) AS (total agtype);\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Retorna vértices completos',\n",
    "        'query': \"\"\"\n",
    "        SELECT * FROM cypher('exemplo_grafo', $$\n",
    "            MATCH (p:Pessoa) \n",
    "            RETURN p\n",
    "        $$) AS (pessoa agtype);\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Uma propriedade específica',\n",
    "        'query': \"\"\"\n",
    "        SELECT * FROM cypher('exemplo_grafo', $$\n",
    "            MATCH (p:Pessoa) \n",
    "            RETURN p.nome\n",
    "        $$) AS (nome agtype);\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Múltiplas propriedades',\n",
    "        'query': \"\"\"\n",
    "        SELECT * FROM cypher('exemplo_grafo', $$\n",
    "            MATCH (p:Pessoa) \n",
    "            RETURN p.nome, p.idade, p.profissao\n",
    "        $$) AS (nome agtype, idade agtype, profissao agtype);\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "with ag.connection.cursor() as cursor:\n",
    "    for test in tests:\n",
    "        print(f\"\\n=== {test['nome'].upper()} ===\")\n",
    "        try:\n",
    "            cursor.execute(test['query'])\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "            print(f\"Sucesso: {len(results)} resultado(s)\")\n",
    "            for i, row in enumerate(results[:3]):  # Mostrar até 3 resultados\n",
    "                print(f\"  {i+1}: {row}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fc269-b426-4878-b831-7d6f848b2de2",
   "metadata": {},
   "source": [
    "## Pyspark\n",
    "\n",
    "\n",
    "Atualmente não tem como executar consultas ou ler/escrever vertices arestas.\n",
    "\n",
    "ISSUE: https://github.com/apache/age/issues/1122\n",
    "        \n",
    "        \n",
    "Mesmo usando o protocolo JDBC, não é possível, pois a cada sessão é necessário fazer o LOAD do age.\n",
    "\n",
    "https://age.apache.org/age-manual/master/intro/setup.html#post-installation-setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a0c3f3-871c-4e16-a04c-b83f0909c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/09/10 10:50:52 WARN Utils: Your hostname, lucasmsp-Inspiron-7580 resolves to a loopback address: 127.0.1.1; using 192.168.15.13 instead (on interface wlp3s0)\n",
      "25/09/10 10:50:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/opt/spark-3.3.0/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/lucasmsp/.ivy2/cache\n",
      "The jars for the packages stored in: /home/lucasmsp/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a2564b4a-dbff-4d94-801c-251f6210409b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.6.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      ":: resolution report :: resolve 95ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.6.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a2564b4a-dbff-4d94-801c-251f6210409b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/09/10 10:50:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/09/10 10:50:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AGE-Spark\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69ae032-5025-4211-b7b8-76484b21d88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o113.load.\n: org.postgresql.util.PSQLException: ERROR: function cypher(unknown, unknown) does not exist\n  Dica: No function matches the given name and argument types. You might need to add explicit type casts.\n  Posição: 35\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:498)\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:415)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:134)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:68)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:242)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:171)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1455796/645698103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"password\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"postgresPW\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"driver\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"org.postgresql.Driver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     def json(\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o113.load.\n: org.postgresql.util.PSQLException: ERROR: function cypher(unknown, unknown) does not exist\n  Dica: No function matches the given name and argument types. You might need to add explicit type casts.\n  Posição: 35\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:498)\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:415)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:134)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:68)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:242)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:171)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = \"jdbc:postgresql://localhost:5455/postgres\"\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM cypher('exemplo_grafo', $$\n",
    "        MATCH (p:Pessoa) \n",
    "        RETURN p.nome, p.idade, p.profissao\n",
    "    $$) AS (nome agtype, idade agtype, profissao agtype)\"\"\"\n",
    "\n",
    "vertices_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"query\", query) \\\n",
    "    .option(\"user\", \"postgresUser\") \\\n",
    "    .option(\"password\", \"postgresPW\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f233d-9851-4745-b49b-194646df8b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
