{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6766c77e",
   "metadata": {},
   "source": [
    "# Nebula \n",
    "\n",
    "\n",
    "https://github.com/vesoft-inc/nebula-algorithm (parou no spark 2.4)\n",
    "\n",
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ce73c-a39e-4f20-a789-7cd2e57bb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\n",
    "    \"spark.jars\", \"/home/jovyan/nebula-spark-connector_3.0-3.6.0.jar\"\n",
    ").config(\"spark.driver.extraClassPath\",\"/home/jovyan/nebula-spark-connector_3.0-3.6.0.jar\"\n",
    "        ).config(\"spark.executor.extraClassPath\",\"/home/jovyan/nebula-spark-connector_3.0-3.6.0.jar\"\n",
    "        ).appName(\n",
    "    \"nebula-connector\"\n",
    ").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42597a6-3bf7-4632-881a-dd11b5c7e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\n",
    "  \"com.vesoft.nebula.connector.NebulaDataSource\").option(\n",
    "    \"type\", \"vertex\").option(\n",
    "    \"spaceName\", \"exemplo_grafo\").option(\n",
    "    \"label\", \"pessoa\").option(\n",
    "    \"returnCols\", \"nome,idade,profissao\").option(\"metaAddress\", \"metad0:9559,metad1:9559,metad2:9559\") \\\n",
    "    .option(\"graphAddress\", \"graphd:9669,graphd1:9669,graphd2:9669\") \\\n",
    "    .option(\"operateType\", \"read\").option(\"partitionNumber\", 1).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27661c47-183f-493c-922e-4c75cde66a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----+----------+\n",
      "|_vertexId|        nome|idade| profissao|\n",
      "+---------+------------+-----+----------+\n",
      "|     p004|   Ana Costa|   31|  Analista|\n",
      "|     p001|  João Silva|   35|Engenheiro|\n",
      "|     p002|Maria Santos|   29|  Designer|\n",
      "|     p003| Carlos Lima|   42|   Gerente|\n",
      "+---------+------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3af501e-3fca-4e0a-9439-552a88f554df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+---------+\n",
      "|_vertexId|       nome|idade|profissao|\n",
      "+---------+-----------+-----+---------+\n",
      "|     p005|Lucas Ponce|   35|Estudante|\n",
      "+---------+-----------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando um DataFrame com dados de jogadores de basquete\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"_vertexId\", StringType(), True),\n",
    "    StructField(\"nome\", StringType(), True),\n",
    "    StructField(\"idade\", IntegerType(), True),\n",
    "    StructField(\"profissao\", StringType(), True)\n",
    "])\n",
    "\n",
    "players_data = [\n",
    "    (\"p005\", \"Lucas Ponce\", 35, \"Estudante\"),\n",
    "]\n",
    "\n",
    "df_players = spark.createDataFrame(players_data, schema)\n",
    "\n",
    "df_players.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9db6e9be-7236-4d4f-b2ac-fd48b4228f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo vértices no NebulaGraph\n",
    "df_players.write.format(\"com.vesoft.nebula.connector.NebulaDataSource\").mode(\"append\")\\\n",
    ".option(\n",
    "    \"type\", \"vertex\"\n",
    ").option(\n",
    "    \"operateType\", \"write\"\n",
    ").option(\n",
    "    \"spaceName\", \"exemplo_grafo\"\n",
    ").option(\n",
    "    \"label\", \"pessoa\"\n",
    ").option(\n",
    "    \"vidPolicy\", \"\"\n",
    ").option(\n",
    "    \"vertexField\", \"_vertexId\"\n",
    ").option(\n",
    "    \"batch\", 100\n",
    ").option(\n",
    "    \"metaAddress\", \"metad0:9559,metad1:9559,metad2:9559\"\n",
    ").option(\n",
    "    \"graphAddress\", \"graphd:9669,graphd1:9669,graphd2:9669\"\n",
    ").option(\n",
    "    \"user\", \"root\"\n",
    ").option(\n",
    "    \"passwd\", \"\"\n",
    ").option(\n",
    "    \"writeMode\", \"insert\"\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b13046fb-e76e-498c-abd6-219bd0b7fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----+----------+\n",
      "|_vertexId|        nome|idade| profissao|\n",
      "+---------+------------+-----+----------+\n",
      "|     p004|   Ana Costa|   31|  Analista|\n",
      "|     p001|  João Silva|   35|Engenheiro|\n",
      "|     p002|Maria Santos|   29|  Designer|\n",
      "|     p005| Lucas Ponce|   35| Estudante|\n",
      "|     p003| Carlos Lima|   42|   Gerente|\n",
      "+---------+------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\n",
    "  \"com.vesoft.nebula.connector.NebulaDataSource\").option(\n",
    "    \"type\", \"vertex\").option(\n",
    "    \"spaceName\", \"exemplo_grafo\").option(\n",
    "    \"label\", \"pessoa\").option(\n",
    "    \"returnCols\", \"nome,idade,profissao\").option(\"metaAddress\", \"metad0:9559,metad1:9559,metad2:9559\") \\\n",
    "    .option(\"graphAddress\", \"graphd:9669,graphd1:9669,graphd2:9669\") \\\n",
    "    .option(\"operateType\", \"read\").option(\"partitionNumber\", 1).load().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b3190c1-c71a-4e9b-b55a-5dd2b6742514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+-------------+\n",
      "|srcid|dstid|     desde|  proximidade|\n",
      "+-----+-----+----------+-------------+\n",
      "| p005| p003|2018-05-20|amigo_proximo|\n",
      "| p002| p005|2018-05-20|amigo_proximo|\n",
      "+-----+-----+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando DataFrame com relacionamentos (ex: equipes que jogaram juntos)\n",
    "from pyspark.sql.types import StructType, StructField, StringType,DateType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "edge_schema = StructType([\n",
    "    StructField(\"srcid\", StringType(), True),\n",
    "    StructField(\"dstid\", StringType(), True),\n",
    "    StructField(\"desde\", StringType(), True),\n",
    "    StructField(\"proximidade\", StringType(), True)\n",
    "])\n",
    "\n",
    "relationships_data = [\n",
    "    (\"p005\", \"p003\",  \"2018-05-20\", \"amigo_proximo\"),\n",
    "    (\"p002\", \"p005\",  \"2018-05-20\", \"amigo_proximo\"),\n",
    "]\n",
    "\n",
    "df_relationships = spark.createDataFrame(relationships_data, edge_schema)\n",
    "df_relationships = df_relationships.withColumn(\"desde\", F.from_unixtime(F.unix_timestamp('desde', 'yyyy-MM-dd')).cast(\"date\"))\n",
    "\n",
    "df_relationships.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d2aa21a-d4f5-4ea1-9d18-f7e704132872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships.write.format(\"com.vesoft.nebula.connector.NebulaDataSource\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"operateType\", \"write\")\\\n",
    "    .option(\"srcPolicy\", \"\")\\\n",
    "    .option(\"dstPolicy\", \"\")\\\n",
    "   .option(\n",
    "        \"metaAddress\", \"metad0:9559,metad1:9559,metad2:9559\"\n",
    "    ).option(\n",
    "        \"graphAddress\", \"graphd:9669,graphd1:9669,graphd2:9669\"\n",
    "    )\\\n",
    "    .option(\"user\", \"root\")\\\n",
    "    .option(\"passwd\", \"\")\\\n",
    "    .option(\"type\", \"edge\")\\\n",
    "    .option(\"spaceName\", \"exemplo_grafo\")\\\n",
    "    .option(\"label\", \"conhece\")\\\n",
    "    .option(\"srcVertexField\", \"srcid\")\\\n",
    "    .option(\"dstVertexField\", \"dstid\")\\\n",
    "    .option(\"batch\", 100)\\\n",
    "    .option(\"writeMode\", \"insert\")\\\n",
    "    .option(\"rankField\", \"\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b877a21f-dc02-4bee-81ed-934a596731df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+-----------+-------------+\n",
      "|_srcId|_dstId|_rank|      desde|  proximidade|\n",
      "+------+------+-----+-----------+-------------+\n",
      "|  p001|  p002|    0| 2018-05-20|amigo_proximo|\n",
      "|  p001|  p004|    0| 2022-08-20|       colega|\n",
      "|  p002|  p003|    0| 2019-12-10|    conhecido|\n",
      "|  p002|  p005|    0|17671-01-01|amigo_proximo|\n",
      "|  p005|  p003|    0|17671-01-01|amigo_proximo|\n",
      "|  p003|  p004|    0| 2022-09-01|       colega|\n",
      "+------+------+-----+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_conhece = spark.read.format(\"com.vesoft.nebula.connector.NebulaDataSource\") \\\n",
    "    .option(\"type\", \"edge\") \\\n",
    "    .option(\"spaceName\", \"exemplo_grafo\") \\\n",
    "    .option(\"label\", \"conhece\") \\\n",
    "    .option(\"returnCols\", \"desde,proximidade\") \\\n",
    "    .option(\"metaAddress\", \"metad0:9559,metad1:9559,metad2:9559\") \\\n",
    "    .option(\"graphAddress\", \"graphd:9669,graphd1:9669,graphd2:9669\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"passwd\", \"nebula\") \\\n",
    "    .option(\"operateType\", \"read\") \\\n",
    "    .option(\"rankField\", \"\") \\\n",
    "    .option(\"partitionNumber\", 1) \\\n",
    "    .load()\n",
    "\n",
    "# Visualizar os dados\n",
    "df_conhece.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05161120-7faa-48e5-b725-f8a720e1ea9a",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559388e1-3f11-4ce2-850a-220a3bf7e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nebula3-python\n",
      "  Downloading nebula3_python-3.8.3-py3-none-any.whl (331 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.3/331.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2021.1 in /opt/conda/lib/python3.10/site-packages (from nebula3-python) (2022.5)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from nebula3-python) (1.16.0)\n",
      "Collecting httpx[http2]>=0.22.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httplib2>=0.20.0\n",
      "  Downloading httplib2-0.30.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting future>=0.18.0\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing<4,>=3.0.4 in /opt/conda/lib/python3.10/site-packages (from httplib2>=0.20.0->nebula3-python) (3.0.9)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx[http2]>=0.22.0->nebula3-python) (3.6.2)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx[http2]>=0.22.0->nebula3-python) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx[http2]>=0.22.0->nebula3-python) (2022.9.24)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h2<5,>=3\n",
      "  Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting hyperframe<7,>=6.1\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting hpack<5,>=4.1\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx[http2]>=0.22.0->nebula3-python) (1.3.0)\n",
      "Installing collected packages: hyperframe, httplib2, hpack, h11, future, httpcore, h2, httpx, nebula3-python\n",
      "Successfully installed future-1.0.0 h11-0.16.0 h2-4.3.0 hpack-4.1.0 httpcore-1.0.9 httplib2-0.30.0 httpx-0.28.1 hyperframe-6.1.0 nebula3-python-3.8.3\n"
     ]
    }
   ],
   "source": [
    "! pip install nebula3-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "134c9275-afdd-4fe4-8b80-c4db2f2c33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebula3.gclient.net import ConnectionPool\n",
    "from nebula3.Config import Config\n",
    "\n",
    "# Configuração da conexão\n",
    "config = Config()\n",
    "config.max_connection_pool_size = 10\n",
    "\n",
    "# Inicializar pool de conexões\n",
    "connection_pool = ConnectionPool()\n",
    "ok = connection_pool.init([('graphd', 9669)], config)\n",
    "\n",
    "if not ok:\n",
    "    print(\"Erro ao conectar com NebulaGraph\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06df46d2-3f86-4472-9418-55198473ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espaços disponíveis:\n",
      "- <bound method Record.values of \"exemplo_grafo\">\n"
     ]
    }
   ],
   "source": [
    "with connection_pool.session_context('root', '') as session:\n",
    "    # Listar todos os espaços\n",
    "    result = session.execute('SHOW SPACES')\n",
    "    print(\"Espaços disponíveis:\")\n",
    "    for row in result:\n",
    "        print(f\"- {row.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa597dc-924c-4e13-ac2a-6d1179923779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
